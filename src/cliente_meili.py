#!/usr/bin/env python3
import os, json, time
import requests
import meilisearch
from sync_hash import filter_changed
from dotenv import load_dotenv
load_dotenv()

MEILI_URL = os.getenv("MEILI_URL", "http://127.0.0.1:7700")
MEILI_KEY = os.getenv("MEILI_MASTER_KEY", "")
OPENAI_KEY = os.getenv("OPENAI_API_KEY", "")

INDEX_UID = "documentos"

client = meilisearch.Client(MEILI_URL, MEILI_KEY)
index = client.index(INDEX_UID)

# ---------------- Helpers ---------------- #

def wait_task(uid):
    """Bloqueia at√© o t√©rmino de uma task (polling leve)."""
    while True:
        task = client.get_task(uid)
        status = task.status
        if status in ("succeeded", "failed", "canceled"):
            if status != "succeeded":
                raise RuntimeError(f"Tarefa {uid} falhou: {task}")
            return
        time.sleep(0.3)

def ensure_index():
    """Garante que o √≠ndice existe (sem erro se j√° existir)."""
    try:
        client.create_index(INDEX_UID, {"primaryKey": "id"})
        print(f"üÜï √çndice '{INDEX_UID}' criado.")
    except meilisearch.errors.MeilisearchApiError:
        print(f"‚ÑπÔ∏è √çndice '{INDEX_UID}' j√° existe.")

# ---------------- Pipeline ---------------- #

def load_docs(path="out/dataset_all.json", batch_size=1000):
    """Carrega e insere apenas documentos novos ou alterados."""
    with open(path, "r", encoding="utf-8") as f:
        docs = json.load(f)

    # üëá Only keep changed/new docs
    docs = filter_changed(docs)

    if not docs:
        print("‚ÑπÔ∏è Nenhum documento novo ou alterado. Pulando indexa√ß√£o.")
        return 0

    total = len(docs)
    print(f"üì¶ Iniciando upsert de {total} documentos (novos/alterados)...")

    for i in range(0, total, batch_size):
        batch = docs[i:i + batch_size]
        task = index.add_documents(batch)
        wait_task(task.task_uid)
        print(f"  ‚Üí Lote {i//batch_size + 1}: {len(batch)} docs")

    return total


def configure_settings():
    """Define campos filtr√°veis, sin√¥nimos e ajustes de ranking para documentos hist√≥ricos."""
    print("‚öôÔ∏è  Configurando atributos e sin√¥nimos...")

    # Campos √∫teis para filtro ou facetas
    task = index.update_filterable_attributes([
        "documento", "pagina", "titulo", "length"
    ])
    wait_task(task.task_uid)

    # Campos vis√≠veis em resultados
    task = index.update_searchable_attributes([
        "texto", "titulo"
    ])
    wait_task(task.task_uid)

    # Campos que aparecem como snippet nos resultados
    task = index.update_displayed_attributes([
        "titulo", "documento", "pagina", "texto"
    ])
    wait_task(task.task_uid)

    # Ranking personalizado: dar mais peso para trechos longos e para o t√≠tulo
    task = index.update_ranking_rules([
        "words",
        "typo",
        "proximity",
        "attribute",
        "exactness",
        "sort",
        "length:desc"
    ])
    wait_task(task.task_uid)

    # Sin√¥nimos √∫teis para o contexto de seguran√ßa, censura e regime militar
    synonyms = {
        "comunista": ["subversivo", "infiltrado", "agitador"],
        "unb": ["universidade de brasilia", "unb"],
        "estudantil": ["movimento estudantil", "alunos", "greve"],
        "seguran√ßa": ["dsi", "asi", "informa√ß√µes", "espionagem"],
        "documento": ["informe", "relat√≥rio", "memorando"],
        "mec": ["ministerio da educacao", "educacao e cultura"]
    }
    task = index.update_synonyms(synonyms)
    wait_task(task.task_uid)

    print("‚úÖ Configura√ß√£o b√°sica e sin√¥nimos aplicados.")

def configure_embedder():
    """Configura busca sem√¢ntica via OpenAI (via REST API, idempotente)."""
    if not OPENAI_KEY:
        print("‚ö†Ô∏è  OPENAI_API_KEY n√£o definido. Pulando embedder.")
        return

    print("üß† Verificando embedder existente...")

    # Step 1: check current embedders
    resp = requests.get(
        f"{MEILI_URL}/indexes/{INDEX_UID}/settings/embedders",
        headers={"Authorization": f"Bearer {MEILI_KEY}"},
        timeout=30,
    )
    if not resp.ok:
        raise RuntimeError(f"Erro ao consultar embedders: {resp.status_code} {resp.text}")

    embedders = resp.json()
    if "documentos-openai" in embedders:
        print("‚ÑπÔ∏è  Embedder j√° configurado. Pulando recria√ß√£o.")
        return

    # Step 2: create only if missing
    print("üß† Configurando embedder OpenAI (contexto hist√≥rico/pol√≠tico)...")

    payload = {
        "documentos-openai": {
            "source": "openAi",
            "apiKey": OPENAI_KEY,
            "model": "text-embedding-3-small",
            "documentTemplate": (
                "Relat√≥rio hist√≥rico de seguran√ßa nacional ou universit√°ria. "
                "T√≠tulo: '{{doc.titulo}}'. "
                "Conte√∫do: '{{doc.texto}}'"
            ),
        }
    }

    r = requests.patch(
        f"{MEILI_URL}/indexes/{INDEX_UID}/settings/embedders",
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {MEILI_KEY}",
        },
        json=payload,
        timeout=60,
    )
    if not r.ok:
        raise RuntimeError(f"Erro configurando embedder: {r.status_code} {r.text}")

    print("‚úÖ Embedder configurado com sucesso.")

def wait_for_embeddings_ready():
    """Waits until all embedding generation tasks finish."""
    print("üïí Aguardando finaliza√ß√£o das embeddings...")

    while True:
        r = requests.get(
            f"{MEILI_URL}/tasks",
            headers={"Authorization": f"Bearer {MEILI_KEY}"},
            timeout=30,
        )
        r.raise_for_status()
        tasks = r.json().get("results", [])

        # Filter embedding generation tasks
        pending = [
            t for t in tasks
            if t.get("type") == "indexEmbeddingGeneration"
            and t.get("indexUid") == INDEX_UID
            and t.get("status") not in ("succeeded", "failed", "canceled")
        ]

        if not pending:
            print("‚úÖ Todas as embeddings foram geradas.")
            return

        # Show short status summary
        statuses = [t["status"] for t in pending]
        print(f"  ‚Üí Aguardando {len(pending)} tarefa(s): {statuses}")
        time.sleep(5)

def sanity_queries():
    """Executa buscas de teste representativas."""
    print("\nüîç Testando consultas:")
    print("‚Üí Full-text (palavras-chave diretas):")
    res1 = index.search("infiltra√ß√£o comunista UnB", {"limit": 3})
    for hit in res1["hits"]:
        print(f"  - {hit['titulo']} (p.{hit['pagina']})")

    print("\n‚Üí Sem√¢ntica (busca contextual OpenAI):")
    res2 = index.search("documentos sobre vigil√¢ncia de estudantes em Bras√≠lia",
        {
            "hybrid": {"semanticRatio": 0.7, "embedder": "documentos-openai"},
            "limit": 1
        }
    )
    for hit in res2["hits"]:
        print(f"  - {hit['titulo']} (p.{hit['pagina']})")


# ---------------- Main ---------------- #
if __name__ == "__main__":
    ensure_index()
    total = load_docs("out/dataset_all.json")
    print(f"‚úÖ Upsert completo: {total} registros inseridos.")
    configure_settings()
    configure_embedder()
    wait_for_embeddings_ready()
    sanity_queries()
